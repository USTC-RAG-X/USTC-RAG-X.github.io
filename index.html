<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Deformable Neural Radiance Fields creates free-viewpoint portraits (nerfies) from casually captured videos.">
  <meta name="keywords" content="Nerfies, D-NeRF, NeRF">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>PruningRAG</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
  <style>
    table {
        padding: 0;
        word-break: initial;
    }
    table tr {
        border: 1px solid #dfe2e5;
        margin: 0;
        padding: 0;
    }
    table tr:nth-child(2n),
    thead {
        background-color: #f8f8f8;
    }
    table th {
        font-weight: bold;
        border: 1px solid #dfe2e5;
        border-bottom: 0;
        margin: 0;
        padding: 6px 13px;
    }
    table td {
        border: 1px solid #dfe2e5;
        margin: 0;
        padding: 6px 13px;
    }
    table th:first-child,
    table td:first-child {
        margin-top: 0;
    }
    table th:last-child,
    table td:last-child {
        margin-bottom: 0;
    }
    h1 {
        font-size: 2.25em;
        line-height: 1.2;
        border-bottom: 1px solid #eee;
    }
    h2 {
        font-size: 1.75em;
        line-height: 1.225;
        border-bottom: 1px solid #eee;
    }
  </style>
</head>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://github.com/USTCAGI">
        <span class="icon">
          <i class="fas fa-home"></i>
        </span>
      </a>

      <!-- <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://spreadsheetbench.github.io/">
            SpreadsheetBench
          </a>
        </div>
      </div> -->
    </div>

  </div>
</nav>

<body>
  <section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h2 class="title is-1 publication-title">PruningRAG:  Multi-Source Knowledge Pruning for RAG</h2>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- arXiv Papers Link (Single Row) -->
              <div style="margin-bottom: 20px;">
                <span class="link-block">
                  <button id="show-papers" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="ai ai-arxiv"></i>
                    </span>
                    <span>arXiv Papers</span>
                  </button>
                </span>
              </div>

              <!-- Hidden Paper Links (Below arXiv Papers Button) -->
              <div id="paper-links" style="display: none; margin-bottom: 20px;">
                <span class="link-block">
                  <a href="https://arxiv.org/abs/2409.13694"
                     class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                        <i class="ai ai-arxiv"></i>
                    </span>
                    <span>A Knowledge-Centric Benchmarking Framework</span>
                  </a>
                </span>

                <span class="link-block">
                  <a href="https://arxiv.org/abs/2409.15337"
                     class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                        <i class="ai ai-arxiv"></i>
                    </span>
                    <span>Revisiting the Solution of Meta KDD Cup 2024</span>
                  </a>
                </span>
              </div>

              <!-- Code and Dataset Links (Same Row) -->
              <div style="display: flex; justify-content: center; gap: 20px;">
                <!-- Code Link -->
                <span class="link-block">
                  <a href="https://github.com/USTCAGI/PruningRAG"
                     class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                        <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                    </a>
                </span>

                <!-- Dataset Link -->
                <span class="link-block">
                  <a href="https://huggingface.co/datasets/fishsure/RM3QA"
                      class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                        <i class="far fa-images"></i>
                    </span>
                    <span>Data</span>
                  </a>
                </span>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<script>
  document.getElementById('show-papers').addEventListener('click', function() {
    var paperLinks = document.getElementById('paper-links');
    if (paperLinks.style.display === 'none') {
      paperLinks.style.display = 'block';
    } else {
      paperLinks.style.display = 'none';
    }
  });
</script>

  
  

  

<!-- <section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video id="teaser" autoplay muted loop playsinline height="100%">
        <source src="./static/videos/platform.mp4"
                type="video/mp4">
      </video>
      <h2 class="subtitle has-text-centered">
        <span class="dnerf">Table Manipulation using TableLLM on our platform
      </h2>
    </div>
  </div>
</section> -->

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>

            Retrieval-augmented generation (RAG) is increasingly recognized as an effective approach for mitigating the hallucination of large language models (LLMs) through the integration of external knowledge. While numerous efforts, most studies focus on a single type of external knowledge source. However, in real-world applications, most situations involve diverse knowledge from various sources, yet this area has been less explored. The main dilemma is the lack of a suitable dataset containing multiple knowledge sources and pre-exploration of the associated issues. To address these challenges, we standardize a benchmark dataset that combines structured and unstructured knowledge across diverse and complementary domains. Based on this dataset, we further develop a plug-and-play RAG framework, PruningRAG, whose main characteristic is to employ multi-granularity pruning strategies for optimizing the integration of relevant information and minimizing misleading context. Building upon the standardized dataset and PruningRAG, we also report a series of experimental results, as well as insightful findings. Our dataset and code are publicly available <a href="https://github.com/USTCAGI/PruningRAG" target="_blank">here</a>, with the aim of advancing future research in the RAG community.
           </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

    <!-- Overview -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Overview</h2>
        <div class="publication-video">
          <img src="static/images/framework1_00.png"/>
        </div>
      </div>
    </div>
    <!--/ Overview -->
  </div>



  <div class="container is-max-desktop">
    <!-- Benchmark Evaluation Section -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Benchmark Evaluation of RAG</h2>
        <div class="content has-text-justified"></div>
        <div class="table-container">
          <table class="table is-bordered is-striped is-narrow is-hoverable is-fullwidth">
            <caption>Table 1: Comparative analysis of RAG performance across different external knowledge configurations.</caption>
            <thead>
              <tr>
                <th>External Knowledge</th>
                <th>Method</th>
                <th>Acc.</th>
                <th>Halluc.</th>
                <th>Miss.</th>
                <th>Score</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td>None</td>
                <td>LLM-Only</td>
                <td>15.61%</td>
                <td>20.42%</td>
                <td>63.97%</td>
                <td>-4.81%</td>
              </tr>
              <tr>
                <td rowspan="3">5 Web pages</td>
                <td>Naive RAG</td>
                <td>7.51%</td>
                <td><b>8.68%</b></td>
                <td>83.81%</td>
                <td>-1.16%</td>
              </tr>
              <tr>
                <td>HyDE</td>
                <td>24.36%</td>
                <td>17.72%</td>
                <td>57.91%</td>
                <td>6.64%</td>
              </tr>
              <tr>
                <td>PruningRAG</td>
                <td><b>27.64%</b></td>
                <td>18.16%</td>
                <td>54.19%</td>
                <td><b>9.48%</b></td>
              </tr>
              <tr>
                <td rowspan="3">Mock API</td>
                <td>Naive RAG</td>
                <td>8.53%</td>
                <td><b>1.60%</b></td>
                <td>89.86%</td>
                <td>6.93%</td>
              </tr>
              <tr>
                <td>HyDE</td>
                <td>19.84%</td>
                <td>11.09%</td>
                <td>69.07%</td>
                <td>8.75%</td>
              </tr>
              <tr>
                <td>PruningRAG</td>
                <td><b>29.03%</b></td>
                <td>10.86%</td>
                <td>60.10%</td>
                <td><b>18.16%</b></td>
              </tr>
              <tr>
                <td rowspan="3">5 Web pages + Mock API</td>
                <td>Naive RAG</td>
                <td>15.10%</td>
                <td><b>7.95%</b></td>
                <td>76.95%</td>
                <td>7.15%</td>
              </tr>
              <tr>
                <td>HyDE</td>
                <td>22.07%</td>
                <td>21.88%</td>
                <td>56.09%</td>
                <td>0.15%</td>
              </tr>
              <tr>
                <td>PruningRAG</td>
                <td><b>44.64%</b></td>
                <td>17.58%</td>
                <td>37.78%</td>
                <td><b>27.06%</b></td>
              </tr>
              <tr>
                <td rowspan="3">50 Web pages + Mock API</td>
                <td>Naive RAG</td>
                <td>14.22%</td>
                <td><b>8.90%</b></td>
                <td>76.88%</td>
                <td>5.32%</td>
              </tr>
              <tr>
                <td>HyDE</td>
                <td>32.68%</td>
                <td>19.69%</td>
                <td>47.63%</td>
                <td>12.99%</td>
              </tr>
              <tr>
                <td>PruningRAG</td>
                <td><b>38.73%</b></td>
                <td>14.59%</td>
                <td>46.68%</td>
                <td><b>24.14%</b></td>
              </tr>
            </tbody>
          </table>
        </div>
      </div>
    </div>
  </div>

  


  </section>
  

  <section class="section">
    <div class="container is-max-desktop">
      <!-- Empirical Study Section -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Empirical Study</h2>
          
          <!-- Knowledge Source Selection Subsection -->
          <div class="content has-text-justified">
            <h3 class="title is-4">Knowledge Source Selection</h3>
            <p>
              This section discusses the importance of selecting the right knowledge sources for RAG frameworks. The effectiveness of the generated responses depends heavily on the quality and relevance of the external knowledge sources. Various selection strategies are compared to determine the optimal method for different types of queries.
            </p>
                      <!-- Table for Knowledge Source Selection -->
                      <div class="table-container">
                        <table class="table is-bordered is-striped is-narrow is-hoverable is-fullwidth">
                          <caption>Table 2: Comparison of performance of different strategies for leveraging knowledge sources.</caption>
                          <thead>
                            <tr>
                              <th>Experiment Setting</th>
                              <th>Acc.</th>
                              <th>Score</th>
                            </tr>
                          </thead>
                          <tbody>
                            <tr>
                              <td>LLM</td>
                              <td>17.94%</td>
                              <td>-0.36%</td>
                            </tr>
                            <tr>
                              <td>Web pages</td>
                              <td>27.64%</td>
                              <td>9.48%</td>
                            </tr>
                            <tr>
                              <td>Mock API</td>
                              <td>34.43%</td>
                              <td>24.43%</td>
                            </tr>
                            <tr>
                              <td>Both</td>
                              <td>40.26%</td>
                              <td>18.31%</td>
                            </tr>
                            <tr>
                              <td>LLM+Web pages</td>
                              <td>17.94%</td>
                              <td>7.80%</td>
                            </tr>
                            <tr>
                              <td>LLM+Mock API</td>
                              <td>40.55%</td>
                              <td>22.25%</td>
                            </tr>
                            <tr>
                              <td>LLM+Both</td>
                              <td><b>45.73%</b></td>
                              <td>14.37%</td>
                            </tr>
                            <tr>
                              <td>LLM → Web pages</td>
                              <td>25.30%</td>
                              <td>-5.84%</td>
                            </tr>
                            <tr>
                              <td>LLM → Mock API</td>
                              <td>35.01%</td>
                              <td>11.31%</td>
                            </tr>
                            <tr>
                              <td>LLM → Both</td>
                              <td>38.22%</td>
                              <td>6.64%</td>
                            </tr>
                            <tr>
                              <td>Knowledge Source Pruning</td>
                              <td>40.34%</td>
                              <td><b>27.72%</b></td>
                            </tr>
                          </tbody>
                        </table>
                      </div>
                      
        

          </div>
          
          <!-- Retrieval for Knowledge Extraction Subsection -->
          <div class="content has-text-justified">
            <h3 class="title is-4">Retrieval for Knowledge Extraction</h3>
            <p>
              Retrieval is a crucial step in the RAG process. In this subsection, we analyze different retrieval techniques and their performance in extracting relevant information from knowledge sources. We also explore the trade-offs between speed and accuracy in various retrieval methods.
            </p>
          
          <!-- First Table for Retrieval Comparison -->
           <p>
            Table 3  compares the performance of the RAG system with and without a broad retrieval step, where each query is supplemented with 50 web pages—far more than the 5 used in other experiments. The results demonstrate that this broad retrieval phase significantly enhances system efficiency, notably reducing processing time. Sparse retrieval methods like BM25 filter out irrelevant data, allowing dense retrieval to focus on a more targeted subset of external knowledge. 
          </p>
          <div class="table-container">
            <table class="table is-bordered is-striped is-narrow is-hoverable is-fullwidth">
              <caption>Table 3: Comparison of effectiveness and efficiency with and without broad retrieval.</caption>
              <thead>
                <tr>
                  <th>Setting</th>
                  <th>Acc.</th>
                  <th>Hall.</th>
                  <th>Latency (s)</th>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td>Broad Retrieval (w/)</td>
                  <td><b>28.96%</b></td>
                  <td>25.09%</td>
                  <td><b>3.29</b></td>
                </tr>
                <tr>
                  <td>Broad Retrieval (w/o)</td>
                  <td>28.95%</td>
                  <td><b>24.36%</b></td>
                  <td>33.54</td>
                </tr>
              </tbody>
            </table>
          </div>
          

          <p> 
            Figure 1 illustrates the trade-offs between dense and sparse retrieval configurations in a RAG system. While higher dense retrieval ratios boost accuracy due to richer semantic understanding, they also elevate hallucination rates, suggesting a risk of contextual misalignment. Conversely, increasing sparse retrieval may lower accuracy and fails to consistently reduce hallucinations, likely because of its dependence on surface-level keyword matching.
          </p>
          <!-- Figure for Retrieval Methods Comparison -->
          <figure class="image is-centered">
            <img src="static/images/Dense_Sparse1.png" alt="Performance of varying retrieval methods in RAG">
            <figcaption>Figure 1: Performance of varying retrieval methods in RAG.</figcaption>
          </figure>

          <!-- Second Table for Reranker Configurations -->
           <p>
            Table 4 summarizes the impact of various reranker configurations on RAG system performance, focusing on different retrieval chunk sizes. The results show that as the number of retrieved chunks increases,  hallucination  rates rise, while accuracy remains stable, suggesting that the reranker performs better with smaller, more focused sets.
          </p>
          <div class="table-container">
            <table class="table is-bordered is-striped is-narrow is-hoverable is-fullwidth">
              <caption>Table 4: Performance of reranker configurations in RAG.</caption>
              <thead>
                <tr>
                  <th>Config.</th>
                  <th>Acc.</th>
                  <th>Halluc.</th>
                  <th>Miss.</th>
                  <th>Score</th>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td>(3, 3)</td>
                  <td>24.14%</td>
                  <td><b>20.42%</b></td>
                  <td>55.43%</td>
                  <td><b>3.72%</b></td>
                </tr>
                <tr>
                  <td>(3, 5)</td>
                  <td>23.85%</td>
                  <td>22.68%</td>
                  <td>53.46%</td>
                  <td>1.17%</td>
                </tr>
                <tr>
                  <td>(3, 10)</td>
                  <td>24.51%</td>
                  <td>23.05%</td>
                  <td>52.44%</td>
                  <td>1.46%</td>
                </tr>
                <tr>
                  <td>(3, 20)</td>
                  <td>25.38%</td>
                  <td>23.34%</td>
                  <td>51.28%</td>
                  <td>2.04%</td>
                </tr>
                <tr>
                  <td>(3, All)</td>
                  <td><b>25.46%</b></td>
                  <td>23.41%</td>
                  <td>51.13%</td>
                  <td>2.04%</td>
                </tr>
              </tbody>
            </table>
            <p class="has-text-justified">
              <em>Note:</em> (3, X) denotes retrieval of X chunks, with (3, All) indicating all chunks passed directly.
            </p>
          </div>
          
  
          <!-- Knowledge Reasoning Subsection -->
          <div class="content has-text-justified">
            <h3 class="title is-4">Knowledge Reasoning</h3>
            <p>
              Once the relevant knowledge is extracted, reasoning over this information becomes essential. This subsection delves into different reasoning techniques and how they can be effectively combined with retrieval results to generate coherent and accurate responses.
            </p>

            <p> 
              Figure 2 illustrates the context-dependent impact of incorporating Chain of Thought (CoT) into RAG systems. While CoT aims to enhance logical reasoning, the results indicate that it does not consistently improve performance and can sometimes reduce accuracy, especially when dealing with multiple conflicting knowledge sources.            </p>
            <!-- Figure for Retrieval Methods Comparison -->
            <figure class="image is-centered">
              <img src="static/images/cot.png" alt="Impact of CoT across knowledge sources">
              <figcaption>Figure 2: Impact of CoT across knowledge sources.</figcaption>
            </figure>


            <p>Table 5 presents the impact of few-shot learning on RAG systems, particularly in identifying false premises across various domains. The results show that the model performs best under 0-shot conditions. However, as more examples are introduced, performance on these questions declines due to overfitting and noise. Despite this, overall accuracy improves with few-shot examples, which provide task-specific guidance. Cross-domain examples also enhance generalization and reduce hallucination rates, demonstrating the value of diverse examples in broadening the model's adaptability across different query types.</p>
            <div class="table-container">
              <table class="table is-bordered is-striped is-narrow is-hoverable is-fullwidth">
                <caption>Table 5: Impact of few-shot learning on LLM reasoning.</caption>
                <thead>
                  <tr>
                    <th>Category</th>
                    <th>N</th>
                    <th>Acc.</th>
                    <th>Hall.</th>
                    <th>Miss.</th>
                    <th>Score</th>
                  </tr>
                </thead>
                <tbody>
                  <tr>
                    <td rowspan="7">Overall</td>
                    <td>0</td>
                    <td>13.20%</td>
                    <td><b>10.50%</b></td>
                    <td>76.29%</td>
                    <td>2.70%</td>
                  </tr>
                  <tr>
                    <td>1</td>
                    <td>16.05%</td>
                    <td>12.62%</td>
                    <td>71.33%</td>
                    <td>3.43%</td>
                  </tr>
                  <tr>
                    <td>2</td>
                    <td>16.12%</td>
                    <td>12.98%</td>
                    <td>70.90%</td>
                    <td>3.14%</td>
                  </tr>
                  <tr>
                    <td>3</td>
                    <td>15.17%</td>
                    <td>12.69%</td>
                    <td>72.14%</td>
                    <td>2.48%</td>
                  </tr>
                  <tr>
                    <td>1*</td>
                    <td>16.12%</td>
                    <td>11.89%</td>
                    <td>71.99%</td>
                    <td>4.23%</td>
                  </tr>
                  <tr>
                    <td>2*</td>
                    <td><b>18.02%</b></td>
                    <td>11.23%</td>
                    <td>70.75%</td>
                    <td><b>6.78%</b></td>
                  </tr>
                  <tr>
                    <td>3*</td>
                    <td>16.41%</td>
                    <td>11.60%</td>
                    <td>72.00%</td>
                    <td>4.81%</td>
                  </tr>
                  <tr>
                    <td rowspan="7">False Premise</td>
                    <td>0</td>
                    <td><b>25.00%</b></td>
                    <td><b>5.77%</b></td>
                    <td>69.23%</td>
                    <td><b>19.23%</b></td>
                  </tr>
                  <tr>
                    <td>1</td>
                    <td>16.03%</td>
                    <td>14.10%</td>
                    <td>69.87%</td>
                    <td>1.93%</td>
                  </tr>
                  <tr>
                    <td>2</td>
                    <td>16.57%</td>
                    <td>13.46%</td>
                    <td>69.87%</td>
                    <td>3.11%</td>
                  </tr>
                  <tr>
                    <td>3</td>
                    <td>17.31%</td>
                    <td>12.82%</td>
                    <td>69.87%</td>
                    <td>4.49%</td>
                  </tr>
                  <tr>
                    <td>1*</td>
                    <td>20.51%</td>
                    <td>12.18%</td>
                    <td>67.31%</td>
                    <td>8.33%</td>
                  </tr>
                  <tr>
                    <td>2*</td>
                    <td>19.87%</td>
                    <td>11.54%</td>
                    <td>68.59%</td>
                    <td>6.33%</td>
                  </tr>
                  <tr>
                    <td>3*</td>
                    <td>23.08%</td>
                    <td>9.62%</td>
                    <td>67.30%</td>
                    <td>13.46%</td>
                  </tr>
                </tbody>
                <tfoot>
                  <tr>
                    <td colspan="6"><i>Note:</i> <b>N*</b> indicates that the N examples provided for in-context learning are cross-domain examples.</td>
                  </tr>
                </tfoot>
              </table>
            </div>
            
          <p>Figure 3 illustrates the effect of query position within the prompt on RAG system performance. The results show that placing the query after the reference information not only increases accuracy but also reduces hallucination rates, suggesting that the model benefits from having more context before addressing the query. </p>
          <figure class="image is-centered"></figure>
            <img src="static/images/query_position.png" alt="Impact of query position within prompt">
            <figcaption>Figure 3: Impact of query position within prompt.</figcaption>
          </figure>

          <p>Figure 4 illustrates the impact of varying noise chunks on RAG system performance. The results show that as the number of noise chunks increases, accuracy initially dips but then improves, reaching its peak at moderate noise levels. Interestingly, while hallucination rates rise with the introduction of noise, they tend to stabilize and slightly decrease at higher noise levels. This suggests that a certain degree of noise may prompt the model to better filter out irrelevant information.</p>
          <figure class="image is-centered"></figure>
            <img src="static/images/noise.png" alt="Performance comparison based on noise chunk quantity in RAG">
            <figcaption>Figure 4: Performance comparison based on noise chunk quantity in RAG.</figcaption>
          </figure>


          </div>

          
          <!-- Impact of Hyperparameter Configurations Subsection -->
          <div class="content has-text-justified">
            <h3 class="title is-4">Impact of Hyperparameter Configurations</h3>
            <p>
              The performance of RAG frameworks can be significantly influenced by the choice of hyperparameters. In this subsection, we present a detailed study on the impact of various hyperparameter configurations and provide recommendations for optimal settings based on different scenarios.
            </p>



          <figure class="image is-centered"></figure>
            <img src="static/images/chunk_size.png" alt="Effect of chunk size on RAG performance">
            <figcaption>Figure 5: Effect of chunk size on RAG performance.</figcaption>
          </figure>


          <figure class="image is-centered"></figure>
            <img src="static/images/chunk_overlap.png" alt="Impact of chunk overlap on RAG performance">
            <figcaption>Figure 6: Impact of chunk overlap on RAG performance.</figcaption>
          </figure>






      

          </div>
        </div>
      </div>
    </div>
  </section>

  

  
<section class="section">
  <div class="container is-max-desktop">
    <!-- Contact -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Contact</h2>
        <div class="content has-text-justified">
          <p>
            If you have any questions, we encourage you to either create Github issues 
            or get in touch with us at <a href="mailto:rag_ustc@icanary.cn">rag_ustc@icanary.cn</a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>

<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            <b>This webpage is intended for academic purposes, not for commercial promotion.</b>
          </p>
          <p>
            It is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            This means you are free to borrow the <a
              href="https://github.com/nerfies/nerfies.github.io">source code</a> of this website.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
